{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from scipy.stats import zscore\n",
    "\n",
    "import pymanopt\n",
    "from pymanopt.manifolds import Stiefel\n",
    "from pymanopt.optimizers import TrustRegions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# % this data is from an example session:\n",
    "# %   brain region - Left ALM\n",
    "# %   task - delayed response (DR) + water-cued (WC)\n",
    "# %   \n",
    "\n",
    "# % exampleData is a dict containing key/vals:\n",
    "# %   time - time bins corresponding to first dimension of fields 'seq' and\n",
    "# %          'motionEnergy' (aligned to go cue/water drop)\n",
    "# %   seq  - single trial neural firing rates in 5 ms bins and smoothed with\n",
    "# %          causal gaussian kernel (35 ms s.d.). Shape = (time bins, trials,\n",
    "# %          neurons)\n",
    "# %   motionEnergy - motion energy is used to measure amount of movement\n",
    "# %                  at a given frame. The time series has been resampled to \n",
    "# %                  match neural data. Shape = (time bins, trials)\n",
    "# %   moveMask - logical array of shape (time bins, trials). 0 indicates\n",
    "# %              stationarity, 1 indicates moving. This mask was produced from\n",
    "# %              exampleData.motionEnergy using a manually set threshold\n",
    "# %   anm/date - session meta data\n",
    "\n",
    "data = loadmat('exampleData.mat')\n",
    "\n",
    "exampleData = dict()\n",
    "exampleData['anm'] = data['exampleData'][0][0][0] \n",
    "exampleData['date'] = data['exampleData'][0][0][1] \n",
    "exampleData['time'] = data['exampleData'][0][0][2] \n",
    "exampleData['seq'] = data['exampleData'][0][0][3]\n",
    "exampleData['motionEnergy'] = data['exampleData'][0][0][4]\n",
    "exampleData['moveMask'] = data['exampleData'][0][0][5]\n",
    "\n",
    "\n",
    "nBins = exampleData['seq'].shape[0]\n",
    "nTrials = exampleData['seq'].shape[1]\n",
    "nNeurons = exampleData['seq'].shape[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cost_and_egrad(manifold, eigvalsNull, eigvalsPotent, dNull, dPotent, P1, P2, covNull, covPotent):\n",
    "    egrad = None # euclidean gradient\n",
    "\n",
    "    @pymanopt.function.numpy(manifold)\n",
    "    def cost(Q):\n",
    "        Qpotent = Q @ P1\n",
    "        Qnull = Q @ P2\n",
    "        normPotent = np.sum(eigvalsPotent[1:dPotent])\n",
    "        normNull = np.sum(eigvalsNull[1:dNull])\n",
    "        return -0.5 * np.trace(Qpotent.T @ covPotent @ Qpotent) / normPotent - 0.5 * np.trace(Qnull.T @ covNull @ Qnull) / normNull\n",
    "\n",
    "\n",
    "    @pymanopt.function.numpy(manifold)\n",
    "    def euclidean_gradient(Q):\n",
    "        normPotent = np.sum(eigvalsPotent[1:dPotent])\n",
    "        normNull = np.sum(eigvalsNull[1:dNull])\n",
    "        return -covPotent @ Q @ (P1*P1.T) / normPotent - covNull @ Q @ (P2*P2.T) / normNull\n",
    "\n",
    "    return cost, egrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PREPROCESS DATA\n",
    "# choice of normalization/standardization is up to you, here just zscoring\n",
    "\n",
    "temp = exampleData['seq'].reshape((nBins*nTrials,nNeurons))\n",
    "\n",
    "rez = dict() # input data, parameters, and results dictionary\n",
    "rez['N'] = dict() # input data\n",
    "\n",
    "rez['N']['full_cat'] = zscore(temp, axis=0) # (time bins * nTrials, nNeurons)\n",
    "rez['N']['full'] = rez['N']['full_cat'].reshape((nBins,nTrials,nNeurons)); # (time bins, nTrials, nNeurons)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DEFINE DATA TO USE FOR NULL AND POTENT SUBSPACES\n",
    "\n",
    "# for the null subspace, we will use all time points, from all trials, in\n",
    "# which the animal was stationary.\n",
    "moveMask = exampleData['moveMask'][:].reshape(-1) # (time bins * nTrials)\n",
    "rez['N']['null'] = rez['N']['full_cat'][np.logical_not(moveMask),:]\n",
    "\n",
    "# for the potent subspace, we will use all time points, from all trials, in\n",
    "# which the animal was moving.\n",
    "rez['N']['potent'] = rez['N']['full_cat'][np.logical_not(np.logical_not(moveMask)),:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "## COVARIANCE AND DIMENSIONALITY\n",
    "\n",
    "# covariances\n",
    "rez['covNull'] = np.cov(rez['N']['null'].T)\n",
    "rez['covPotent'] = np.cov(rez['N']['potent'].T)\n",
    "\n",
    "# dimensionality of subspaces\n",
    "# here I am hard-coding the number of dimensions to be 7 for both subspaces. However, one\n",
    "# could perform further dimensionality reduction or keep more dimensions or have a different number of dimensions for each subspace.\n",
    "# In our experience, dimensionality >  20 takes an incredibly long time to \n",
    "# optimize over.\n",
    "\n",
    "rez['dNull'] = 7\n",
    "rez['dPotent'] = 7\n",
    "\n",
    "rez['dMax'] = np.max([rez['dNull'], rez['dPotent']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = TrustRegions(verbosity=0)\n",
    "manifold = Stiefel(nNeurons,rez['dNull'] + rez['dPotent'])\n",
    "\n",
    "## TODO\n",
    "# assert(isequal(C1, C1'));\n",
    "# assert(isequal(C2, C2'));\n",
    "\n",
    "# assert(size(C1,1) == size(C2,1));\n",
    "# n = size(C1,1);\n",
    "# dmax = max(d1,d2);\n",
    "# %largest magnitude eigenvalues\n",
    "# eigvals1 = eigs(C1, dmax, 'la'); %hoping that these all eigs are positive, still only divinding by largest algebraic +ve values\n",
    "# eigvals2 = eigs(C2, dmax, 'la');\n",
    "# assert(~any(eigvals1<0), 'eigvals1 <0');\n",
    "# assert(~any(eigvals2<0), 'eigvals2 <0');\n",
    "# P1 = [eye(d1); zeros(d2,d1)];\n",
    "# P2 = [zeros(d1, d2); eye(d2)];\n",
    "# P = {P1,P2};\n",
    "\n",
    "\n",
    "cost, egrad = create_cost_and_egrad(manifold, eigvalsNull, eigvalsPotent, dNull, dPotent, P1, P2, covNull, covPotent)\n",
    "\n",
    "problem = pymanopt.Problem(\n",
    "    manifold,\n",
    "    cost,\n",
    "    euclidean_gradient = egrad,\n",
    "    euclidean_hessian = None,\n",
    ")\n",
    "\n",
    "Q = optimizer.run(problem).point"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "subspaceID",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
